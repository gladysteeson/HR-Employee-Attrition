---
title: "HR-Employee_Attrition"
author: "Gladys Teeson"
date: "6/17/2020"
output: pdf_document
urlcolor: blue
toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Employee attrition is defined as the natural process by which employees leave the workforce – for example, through resignation for personal reasons or retirement – and are not immediately replaced. Attrition is an inevitable part of any business. There will come a time when an employee wants to leave your company – for either personal or professional reasons. Employees are leaving the workforce faster than they are hired, and it is often outside the employer’s control.

But when attrition crosses a particular threshold, it becomes a cause for concern. For example, attrition among minority employee groups could be hurting diversity at your organization. Or, attrition among senior leaders can lead to a significant gap in organizational leadership. So it is important to know where your company stands on the employee attrition curve.

For this project, we will be uncovering the factors that lead to employee attrition using dataset created by IBM data scientists.  The objective is to model an algorithm that could generate new insights for the business on what drives attrition.

## Load Libraries

## Import Dataset

The IBM dataset contains 1470 rows and 35 columns with each row representing information about employees.

We will check for any missing values in the dataset.
The sum comes out to be zero which indicates that there are no NA values.

We will check for any duplicate entries in the dataset too.
We can see that all the rows are unique here.

## Exploratory Data Analysis

First, we will look at the range of age of the employees who leave the company the most.

We can see that the attrition among the young employees are more than the senior employees.

Let's look how Gender effects the attrition.

We can see that males are leaving the company the most.


Travel

Employees with low monthly income tend to leave the company the most.


Employees with job level 4 & 5 show least attrition.

Department

Employees with less travelling distance seem to quit the job more.

Employees with lower job satisfaction left the company the most.


We can see that employees who are single left the company the most.

A larger proportion of overtime employees has left the company.

In the dataset, we notice that some columns have the same value for all employees. We can delete these columns.

We can also delete the columns which are irrelevant to the modeling.

Now we have a dataset with 30 columns.


We wil dscretize the variables now. In this way, the number of values for a given continuous attribute is reduced by dividing the attribute into a range of values. The actual data values are replaced with interval value labels. Machine-learning algorithms are typically recursive; to process large amounts of data a great deal of time is spent to sort the data at every step. It is clear that the smaller the number of distinct values to be ordered, the faster these methods should be. That is why these techniques are particularly beneficial.

Let's look at the structure of our dataset again. We can see that some of the datatypes of the variables are not categorical. We can convert the variables to categorical as below:

It can be observed that all the columns are converted into categorical type.


A correlation plot is also plotted using the corrplot function to visualize the correlation among the attributes.

Attrition Distribution

When we look the attrition distribution, we can see that more people stayed in the company than the people who left the company. 

This makes the dataset imbalanced. An imbalanced data refers to classification problems where one class outnumbers other class by a substantial proportion.An inbalanced dataset will bias the prediction model towards the more common class.

So, we will use the function SMOTE to make our imbalanced dataset to a balanced one.

We can see that our dataset is now balanced:

## Generate Train and Test Sets

We will split our balanced dataset into train set and test set. 80% of our data will be the train set and the rest 20% will be our test set.

# Machine Learning Data Models

## Model 1: Logistic Regression



We will now create a results table to add this accuracy. We will continue to add the accuracies of different models to this same results table.

## Model 2: Random Forest

## Model 3: Extreme Gradient Boosting
